---
title: "Using with the tidyverse"
author: "Sam Albers"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
---

## Source material
This vignette is adapted very heavily from Hadley Wickham's incredible [*R for Data Science*](http://r4ds.had.co.nz/) book. You should support Hadley and the work he does by buying [it](https://www.amazon.com/Data-Science-Transform-Visualize-Model/dp/1491910399).

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warnings = FALSE, message = FALSE, fig.width = 10, fig.height = 6)
```

## Packages
In addition to *weathercan*, you'll need several packages from the *tidyverse*  to complete the following analysis.

```{R pck}
library(weathercan)
library(tibble)
library(dplyr)
library(tidyr)
library(ggplot2)
library(broom)
library(modelr)
library(purrr)
```

## Using weathercan to load in data

Your first decision that you need to make when analyzing data from weather stations across canada is to determine for which stations you'd like to query from Environment and Climate Change Canada. In this example, to keep processing time low, we will query two stations with very long records that happen to be far apart. To make that choice we can use (tidyverse)[http://tidyverse.org/] tools and the included `stations` data frame in this package:

```{R stn_pick, echo = TRUE}
stations %>%
  filter(station_id %in% c(707, 4859, 6693,5397, 2315),
         interval == "day") %>%
  select(prov, station_name, station_id, start, end)
```

These two weather stations will be our test data for this vignette. You can broaden or expand your analysis by choosing different or more station. Our next step is to use the `weather_dl()` function to load in the data. 

The following will take quite some time to download as it is downloading over 100 years of daily data for 5 stations.

```{R load_in, echo = TRUE}
pancan_df <- weather_dl(station_ids = c(707, 4859, 6693,5397, 2315), 
                        interval = "day") %>%
  filter(year >= 1920) %>%
  select(station_name, station_id, prov, lat, lon, elev, climat_id, WMO_id, TC_id, mean_temp, date)
```

## Plot the data
```{r raw_plt}
ggplot(pancan_df, aes(x = date, y = mean_temp, colour = station_name)) +
  geom_point() +
  geom_line()
```

This is quite a large dataset. 

## Creating list-columns
```{r nesting}
pancan_df_nest <- pancan_df %>%
  group_by(station_name, station_id, prov, lat, lon, elev, climat_id, WMO_id, TC_id) %>%
  nest()
pancan_df_nest
```

## Fit some models

Define the model

```{r mod_def}
clim_model <- function(df) {
  lm(mean_temp ~ date, data = df)
}
```

Run the model with the existing data

```{r add_lm}
pancan_df_nest <- pancan_df_nest %>% 
  mutate(model = map(data, clim_model))
pancan_df_nest
```

Then add the residuals to the model

```{r add_resid}
pancan_df_nest <- pancan_df_nest %>% 
  mutate(model = map(data, clim_model),
         resids = map2(data, model, add_residuals)) 
pancan_df_nest
```

## Working with list-columns
We can unnest the results then plot them

### `unnest()`
```{r resid}
resids <- unnest(pancan_df_nest, resids)
resids


ggplot(data = resids, aes(date, resid)) +
  geom_line(aes(group = station_name), alpha = 1 / 3) + 
  geom_point() +
  geom_hline(yintercept = 0) +
  facet_wrap(~ station_name, ncol = 1)
```


### Using broom
```{r broom}
glance_df <- pancan_df_nest %>% 
  mutate(glance = map(model, broom::glance)) %>% 
  unnest(glance, .drop = TRUE) %>%
  select(station_name, prov, r.squared, p.value, AIC)
```

```{r, echo = FALSE}
knitr::kable(glance_df)
```


## Looking at the predictions
```{r pred}
preds <- pancan_df_nest %>% 
  mutate(model = map(data, clim_model),
         preds = map2(data, model, add_predictions)) %>%
  unnest(preds)
preds

ggplot(data = preds, aes(x = date, y = mean_temp, colour = station_name)) +
  geom_point() +
  geom_line(aes(y = pred)) +
  facet_wrap(~ station_name, scales = "free_y", ncol = 1)
```
